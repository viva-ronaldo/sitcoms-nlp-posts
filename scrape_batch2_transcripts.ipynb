{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, subprocess, time, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seinfeld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#os.system('wget http://www.seinfeldscripts.com/seinfeld-scripts.html')\n",
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_link_string = str(subprocess.check_output(['grep','-A 2','href\\|Season','post_nlp_comp/seinfeld-scripts.html']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "episode_link_string[3000:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "episode_links = re.findall('href=\\\" ?((?:The|Male)\\w*\\\\.html?)\\\">([^<]*)', episode_link_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_season, current_episode = 0, 1\n",
    "eps_pos = 0\n",
    "episode_links_w_season = []\n",
    "for row in episode_link_string.split('align=\"middle\"'):\n",
    "    if re.search('Season (\\d)', row) is not None:\n",
    "        current_season = int(re.search('Season (\\d)', row).groups()[0])\n",
    "        #print(current_season)\n",
    "        current_episode = 1\n",
    "    if episode_links[eps_pos][0] in row:\n",
    "        #print('========',row)\n",
    "        #print(episode_links[eps_pos],current_season,current_episode)\n",
    "        episode_links_w_season.append((episode_links[eps_pos][0],\n",
    "                                       current_season, current_episode))\n",
    "        current_episode += 1\n",
    "        eps_pos += 1\n",
    "    if eps_pos == len(episode_links):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[e for e in episode_links_w_season if e[2] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('wget http://www.seinfeldscripts.com/TheAbstinence.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can't handle two-line stage directions - second part\n",
    "#  gets into speaker lines.\n",
    "\n",
    "def process_seinfeld_episode(ep_raw):\n",
    "    scene_count = 0\n",
    "    ep_lines = []\n",
    "    current_line = ''\n",
    "    found_ad_break = False\n",
    "    have_prescene_line = False\n",
    "    for l in ep_raw:\n",
    "        l = re.sub('\\s*<p( align=\"left\")?>', '', l).strip()\n",
    "        l = re.sub('</p>', '', l)\n",
    "        l = re.sub('<br>', '', l)\n",
    "        l = re.sub('&quot;', '\"', l)\n",
    "        l = re.sub('&#146;', '\\'', l)\n",
    "        l = re.sub('&#133;', '...', l)\n",
    "        l = re.sub('&#150;', '-', l)\n",
    "        if scene_count > 0 and \\\n",
    "            ('BeginAd' in l or l == 'END OF ACT 1'):\n",
    "            found_ad_break = True\n",
    "        l = re.sub('<!.*--><.*-->', '', l)\n",
    "        \n",
    "        #print(l)\n",
    "        if scene_count == 0 and \\\n",
    "            ('setting' in l.lower() or '% Opening' in l or \\\n",
    "             'First scene' in l or 'Opening scene' in l or \\\n",
    "             '[Scene' in l or \\\n",
    "             'Jerry\\'s opening' in l or 'Jerry\\'s standup' in l or \\\n",
    "             'pening monologue' in l.lower() or \\\n",
    "             l == 'Monologue:' or l == '[Montage]' or \\\n",
    "             'jerry\\'s apartment' in l.lower() or '[George\\'s Apartment]' in l or \\\n",
    "             l[:6].lower() == 'monk\\'s' or \\\n",
    "             'ACT 1' in l or 'ACT ONE' in l or \\\n",
    "             l[:18].lower() == 'at the comedy club' or \\\n",
    "             #TheDeal needs this specific one\n",
    "             'LEVITAN: Remind me to tell you' in l or \\\n",
    "             #TheGoodSamaritan\n",
    "             '(Jerry is driving alone ' in l or \\\n",
    "             #TheLimo\n",
    "             'Do you think that the people at the airport' in l or \\\n",
    "             #TheVirgin\n",
    "             '% Jerry and George talking near a bar' in l or \\\n",
    "             #TheBizarroJerry\n",
    "             '[JERRY and GEORGE are eating' in l or \\\n",
    "             #TheCalzone\n",
    "             'George in a meeting at Yankee' in l or \\\n",
    "             #TheCartoon\n",
    "             'Some street , Jerry and Kramer walking' in l or \\\n",
    "             #TheChickenRoaster\n",
    "             '% George and Jerry are on the side' in l or \\\n",
    "             #ThePackage\n",
    "             'Elaine at the doctor\\'s' in l or \\\n",
    "             #TheRye\n",
    "             'ELAINE: [thinking] I can\\'t believe' in l or \n",
    "             #TheSerenityNow\n",
    "             '% The Costanzas are driving in the car' in l or \\\n",
    "             #TheSniffingAccountant\n",
    "             'Jerry, George and Elaine at Monk\\'s Caf' in l or \\\n",
    "             #TheVoice\n",
    "             '(Scene: In the' in l or \\\n",
    "             #ThePostponement\n",
    "             '[Jerry: and Elaine: are walking down the street' in l or \\\n",
    "             #TheSlicer\n",
    "             '[Elaine wakes up in bed with Jerry.]' in l or \\\n",
    "             l.strip()[:4] == 'INT.'):\n",
    "            scene_count += 1\n",
    "        elif scene_count > 0 and \\\n",
    "            ('END OF SHOW' in l or '[End]' in l or \\\n",
    "            l[:7] == 'THE END' or l == 'END' or l == 'END!' or \\\n",
    "            'Spellchecked and reformatted' in l or \\\n",
    "            'Spell checked and reformatted' in l or \\\n",
    "            'InstanceEndEditable' in l):\n",
    "            break\n",
    "\n",
    "        if scene_count >= 1:\n",
    "            if re.match('[\\s\\w\\.\\(\\)]*:', l) is not None:\n",
    "                if current_line != '':\n",
    "                    #print(current_line)\n",
    "                    ep_lines.append(current_line)\n",
    "                current_line = l.strip()\n",
    "            elif len(l) > 0 and l[0] not in ['[','(','%','=','*'] and \\\n",
    "                l[:4] not in ['INT.','EXT.','ACT '] and \\\n",
    "                l[:10] != 'END OF ACT' and \\\n",
    "                current_line != '':\n",
    "                current_line = ' '.join([current_line, l.strip()])\n",
    "            elif l[:4] in ['INT.','EXT.'] and ('ESTABLISHING' in l or 'ESTABLSIHING' in l):\n",
    "                #this isn't marked as new scene; we want lines after this but before the new\n",
    "                #   scene start to be put after the new scene start\n",
    "                #but write anything in current_line first\n",
    "                if current_line != '':\n",
    "                    ep_lines.append(current_line)\n",
    "                    current_line = ''\n",
    "                have_prescene_line = True\n",
    "            else: \n",
    "                #print(l)\n",
    "                if '[setting' in l.lower() or '[New scene' in l.lower() or \\\n",
    "                    '[scene' in l.lower() or \\\n",
    "                    (l[:4] in ['INT.','EXT.'] and 'ESTABLISHING' not in l and 'ESTABLSIHING' not in l):\n",
    "                    if current_line != '' and not have_prescene_line:\n",
    "                        ep_lines.append(current_line)\n",
    "                        current_line = ''\n",
    "                    ep_lines.append('Scene %i' % scene_count)\n",
    "                    if current_line != '' and have_prescene_line:\n",
    "                        ep_lines.append(current_line)\n",
    "                        current_line = ''\n",
    "                        have_prescene_line = False\n",
    "                    scene_count += 1\n",
    "                    found_ad_break = False  #don't make another new scene below if it was about to do so\n",
    "\n",
    "            #wait until we've written the current speaker line \n",
    "            #  before inserting the scene break\n",
    "            if found_ad_break and re.match('[\\s\\w\\.]*:', l) is not None:\n",
    "                ep_lines.append('Scene %i' % scene_count)\n",
    "                scene_count += 1\n",
    "                found_ad_break = False\n",
    "            \n",
    "            #It still makes the odd mistake around the ad break I think\n",
    "\n",
    "    #catch last line\n",
    "    if current_line != '':\n",
    "        ep_lines.append(current_line)\n",
    "    \n",
    "    return ep_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TheAbstinence.htm', 'r') as file:\n",
    "    ep_raw = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_lines = process_seinfeld_episode(ep_raw)\n",
    "print('Found {:d} lines and {:d} scenes'.format(len(ep_lines), \n",
    "                                len([l for l in ep_lines if l[:5]=='Scene'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ran this once without writing refmt then went back and fixed function\n",
    "#  to catch the problem ones\n",
    "for ep in episode_links_w_season:\n",
    "    \n",
    "    #Formatting is bad so skip 7, and one is incomplete\n",
    "    if ep[0] in ['TheBris.htm','TheParkingGarage.htm',\n",
    "                 'TheStall.htm','TheSuzie.htm',\n",
    "                 'TheNonFatYogurt.html','TheBizarroJerry.htm',\n",
    "                 'TheChineseWoman.htm',\n",
    "                 'TheWaitOut.htm']:\n",
    "        continue\n",
    "    \n",
    "    os.system('wget http://www.seinfeldscripts.com/{:s}'.format(ep[0]))\n",
    "    \n",
    "    with open(ep[0], 'r') as file:\n",
    "        ep_raw = file.readlines()\n",
    "        \n",
    "    ep_lines = process_seinfeld_episode(ep_raw)\n",
    "    print('{:s}: Found {:d} lines and {:d} scenes'.format(ep[0],len(ep_lines),\n",
    "                                                          len([l for l in ep_lines if l[:5]=='Scene'])))\n",
    "    \n",
    "    if len(ep_lines) > 150:\n",
    "        with open('seinfeld_transcripts/refmt_{:02d}{:02d}.txt'.format(\n",
    "            ep[1], ep[2]), 'w') as f:\n",
    "            for line in ep_lines:\n",
    "                f.write(line+'\\n')\n",
    "        \n",
    "        os.system('rm {:s}'.format(ep[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Married With Children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('wget http://albundy.net/marriedaniac/ate/script.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_link_string = str(subprocess.check_output(['grep','href=\"script','script.html']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_links = re.findall('href=\\\"(script/\\w*\\\\.html)\\\">(\\d{4})', episode_link_string)\n",
    "episode_links = [e for e in episode_links if 'fst' not in e[0] and \\\n",
    "                 'tbl' not in e[0] and 'snd' not in e[0]]\n",
    "episode_links = [e for e in episode_links if e[0] not in \\\n",
    "                 ['script/0101snd.html',\n",
    "                  'script/0101fin.html',\n",
    "                  'script/0101o.html',\n",
    "                  'script/0206fin.html',\n",
    "                  'script/0210fin.html',\n",
    "                  'script/0307fin.html',\n",
    "                  'script/0406fin.html',\n",
    "                  'script/0407fin.html',\n",
    "                  'script/0410fin.html',\n",
    "                  'script/0507fin.html']]\n",
    "#skip some with extra html\n",
    "episode_links = [e for e in episode_links if e[0] not in ['script/0205t.html']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('0401t.html', mode='r', encoding='utf-8', errors='ignore') as f:\n",
    "    ep_raw = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I may not have run this unedited for all episodes at once - took two batches I think\n",
    "#  with a small change to finding speakers\n",
    "\n",
    "def process_marriedwc_episode(ep_raw):\n",
    "    scene_count = 0\n",
    "    ep_lines = []\n",
    "    current_line = ''\n",
    "    found_ad_break = False\n",
    "    for l in ep_raw:\n",
    "        l = re.sub('<u>', '', l)\n",
    "        l = re.sub('</u>', '', l)\n",
    "        l = re.sub('^\\n', '', l)\n",
    "        if len(l) == 0:\n",
    "            continue\n",
    "        \n",
    "        #print(l)\n",
    "        if scene_count == 0 and 'ACT ONE' in l:\n",
    "            scene_count += 1\n",
    "        elif scene_count > 0 and \\\n",
    "            ('END OF SHOW' in l or '[End]' in l or \\\n",
    "            l[:7] == 'THE END' or l == 'END' or l == 'END!'):\n",
    "            break\n",
    "\n",
    "        if scene_count >= 1:\n",
    "            #print(l)\n",
    "            #Find the start of a spoken line\n",
    "            if ((re.match('(^[A-Z\\s0-9\\.]{2,20})\\)?\\s+', l) is not None) or \\\n",
    "                re.match('[\\s\\w\\.\\(\\)]*:', l) is not None) and \\\n",
    "                l[:3] != '   ' and l[0] != '\\t' and \\\n",
    "                l[:6] != 'SCENE ' and l[:4] != 'ACT ' and \\\n",
    "                l[:5] not in ['FLIP ','FADE '] and l[:9] != 'DISSOLVE ' and \\\n",
    "                l[:8] != 'FRIENDS:' and l[:6] != 'WORKER':\n",
    "                if current_line != '':\n",
    "                    #print(current_line)\n",
    "                    ep_lines.append(current_line)\n",
    "                \n",
    "                if re.match('^[\\s\\w\\.\\(\\)]*:', l) is not None:\n",
    "                    l = re.sub('\\s+',' ', l)\n",
    "                #if re.match('^[A-Z\\.]{2,20}', l) is not None and '  ' in l:\n",
    "                else:\n",
    "                    speaker = re.match('(^[A-Z\\s0-9\\.]{2,20})\\)?\\s+', l).groups()[0].strip()\n",
    "                    #can get '(AL   I) am' as speaker\n",
    "                    if '  ' in speaker or '\\t' in speaker:\n",
    "                        speaker = re.sub('\\t','  ', speaker)\n",
    "                        speaker = re.sub('\\s{2,20}','  ', speaker)\n",
    "                        speaker, extra_bit = speaker.split('  ')[:2]\n",
    "                        extra_bit = extra_bit.strip()\n",
    "                        l = re.sub('(^[A-Z\\s0-9\\.]{2,20})\\)?\\s+',speaker+': '+extra_bit+' ', l)\n",
    "                    else:\n",
    "                        l = re.sub('(^[A-Z\\s0-9\\.]{2,20})\\)?\\s+',speaker+': ', l)\n",
    "                    #print(speaker)\n",
    "                \n",
    "                current_line = l.strip()\n",
    "            elif (l[:3] == '   ' or l[0] == '\\t') and current_line != '':\n",
    "                current_line = ' '.join([current_line, l.strip()])\n",
    "            else:\n",
    "                #print(l, l[0]=='\\n', l[0]=='\\t')\n",
    "                if 'SCENE' in l:\n",
    "                    if current_line != '':\n",
    "                        ep_lines.append(current_line)\n",
    "                        current_line = ''\n",
    "                    ep_lines.append('Scene %i' % scene_count)\n",
    "                    scene_count += 1\n",
    "\n",
    "    #catch last line\n",
    "    if current_line != '':\n",
    "        ep_lines.append(current_line)\n",
    "    \n",
    "    return ep_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = process_marriedwc_episode(ep_raw)\n",
    "print('Found {:d} lines'.format(len(tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ep in episode_links:\n",
    "    print(ep)\n",
    "    \n",
    "    os.system('wget http://albundy.net/marriedaniac/ate/{:s}'.format(ep[0]))\n",
    "    \n",
    "    with open(ep[0].split('/')[1], mode='r', encoding='utf-8', errors='ignore') as file:\n",
    "        ep_raw = file.readlines()\n",
    "        \n",
    "    ep_lines = process_marriedwc_episode(ep_raw)\n",
    "    print('{:s}: Found {:d} lines and {:d} scenes'.format(ep[0],len(ep_lines),\n",
    "                                                          len([l for l in ep_lines if l[:5]=='Scene'])))\n",
    "    \n",
    "    if len(ep_lines) > 150:\n",
    "        with open('marriedwc_transcripts/refmt_{:s}.txt'.format(ep[1]), 'w') as f:\n",
    "            for line in ep_lines:\n",
    "                f.write(line+'\\n')\n",
    "        \n",
    "        os.system('rm {:s}'.format(ep[0].split('/')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remainders = glob.glob('[01]*html')\n",
    "remainders = [r[:4] for r in remainders]\n",
    "len(remainders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mop up the remainders - \n",
    "#  0218, 0305, 0607, 0608 have extra html so skip\n",
    "\n",
    "for ep in [e for e in episode_links if e[1] in \\\n",
    "           remainders]:\n",
    "    print(ep)\n",
    "    \n",
    "    with open(ep[0].split('/')[1], mode='r', encoding='utf-8', errors='ignore') as file:\n",
    "        ep_raw = file.readlines()\n",
    "        \n",
    "    ep_lines = process_marriedwc_episode(ep_raw)\n",
    "    print('{:s}: Found {:d} lines and {:d} scenes'.format(ep[0],len(ep_lines),\n",
    "                                                          len([l for l in ep_lines if l[:5]=='Scene'])))\n",
    "    \n",
    "    if len(ep_lines) > 120:\n",
    "        with open('marriedwc_transcripts/refmt_{:s}.txt'.format(ep[1]), 'w') as f:\n",
    "            for line in ep_lines:\n",
    "                f.write(line+'\\n')\n",
    "        \n",
    "        os.system('rm {:s}'.format(ep[0].split('/')[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mechanize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = mechanize.Browser()\n",
    "br.set_handle_robots(False)\n",
    "br.set_handle_equiv(False)\n",
    "br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_list = br.open('https://scrubs.fandom.com/wiki/Category:Scrubs_Episodes').readlines()\n",
    "ep_list = list(map(str, ep_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_scrubs_episode(ep_raw):\n",
    "    ep_raw = [l.replace('<b>','').replace('</b>','').replace('<p>','').replace('</p>','') for l in ep_raw]\n",
    "    ep_raw = [l.replace('<br />','') for l in ep_raw]\n",
    "    ep_raw = [l.strip() for l in ep_raw if (':' in l and 'href' not in l and '<' not in l and 'color-header' not in l) or \\\n",
    "              ('Act' in l and 'headline' in l) or \\\n",
    "              ('Scene' in l and 'headline' in l)]\n",
    "\n",
    "    ep_raw = [l.replace(\"J.D.'s Narration\",\"J.D.'s narration\") for l in ep_raw]\n",
    "    ep_raw = [l.replace(\"J.D.'s thoughts\",\"J.D.'s narration\") for l in ep_raw]\n",
    "    ep_raw = [l.replace(\"J.D.'s Thoughts\",\"J.D.'s narration\") for l in ep_raw]\n",
    "    ep_raw = [l.replace(\"J.D. Thoughts\",\"J.D.'s narration\") for l in ep_raw]\n",
    "    ep_raw = [l.replace(\"JD\",\"J.D.\") for l in ep_raw]\n",
    "    #remove speech intonations\n",
    "    ep_raw = [re.sub('\\[.*?\\]', '', l) for l in ep_raw]\n",
    "    ep_raw = [re.sub('\\(.*?\\)', '', l) for l in ep_raw]\n",
    "    print(len(ep_raw))\n",
    "    \n",
    "    ep_proc = []\n",
    "    scene_count = 0\n",
    "    for l in ep_raw:\n",
    "        if 'Preprocessor node count' in l:\n",
    "            break\n",
    "\n",
    "        if 'The following is a transcript' in l:\n",
    "            continue\n",
    "        if 'headline' in l and ('Act' in l or 'Scene' in l):\n",
    "            scene_count += 1\n",
    "            ep_proc.append('Scene %i' % scene_count)\n",
    "        elif scene_count >= 1:\n",
    "            ep_proc.append(l)\n",
    "\n",
    "    return ep_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "season_counter, ep_counter = 0,0\n",
    "for l in ep_list:\n",
    "    if re.search('>Season \\w*<', l) is not None and 'mw-headline' in l:\n",
    "        season_counter += 1\n",
    "        ep_counter = 0\n",
    "    if 'href=\"https://vignette.wikia' in l and re.search('title=\"[\\s\\w]*\"', l) is not None:\n",
    "        ep_counter += 1\n",
    "        ep_title = re.search('title=\"([\\s\\w]*)\"', l).groups()[0]\n",
    "        print(season_counter, ep_counter, ep_title)\n",
    "        \n",
    "        try:\n",
    "            ep_text = br.open('https://scrubs.fandom.com/wiki/{:s}_transcript'.format(ep_title.replace(' ','_'))).readlines()\n",
    "            ep_text = list(map(lambda l: str(l, 'utf-8'), ep_text))\n",
    "\n",
    "            ep_lines = process_scrubs_episode(ep_text)\n",
    "            #print(len(ep_lines))\n",
    "            #print(pd.Series([l.split(':')[0] for l in ep_lines if ':' in l]).value_counts())\n",
    "\n",
    "            if len(ep_lines) > 150:\n",
    "                with open('scrubs_transcripts/refmt_{:02d}{:02d}.txt'.format(season_counter, ep_counter), 'w') as f:\n",
    "                    for line in ep_lines:\n",
    "                        f.write(line+'\\n')\n",
    "            else:\n",
    "                print('MISSED ONE')\n",
    "        except:\n",
    "            print('No transcript found')\n",
    "            \n",
    "    #if season_counter > 1:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only get a few episodes in s6-9 so deleting these from scrubs_transcripts/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
